@InProceedings{GPIRTpaper,
    Title       = {{GPIRT}: {A} {G}aussian Process Model for Item Response Theory},
    Author      = {JBrandon Duck-Mayr and Roman Garnett and Jacob Montgomery},
    Booktitle   = {Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)},
    Pages       = {520--529},
    Year        = {2020},
    Editor      = {Jonas Peters and David Sontag},
    Volume      = {124},
    Series      = {Proceedings of Machine Learning Research},
    Month       = {8},
    Publisher   = {PMLR},
    pdf         = {http://proceedings.mlr.press/v124/duck-mayr20a/duck-mayr20a.pdf},
    url         = { http://proceedings.mlr.press/v124/duck-mayr20a.html },
    abstract    = {The goal of item response theoretic (IRT) models is to provide estimates of latent traits from binary observed indicators and at the same time to learn the item response funcitons (IRFs) that map from latent trait to observed response. However, in many cases observed behavior can deviate significantly from the parametric assumptions of traditional IRT models. Nonparametric IRT (NIRT) models overcome these challenges by relaxing assumptions about the form of the IRFs, but standard tools are unable to simultaneously estimate flexible IRFs and recover ability estimates for respondents. We propose a Bayesian nonparametric model that solves this problem by placing Gaussian process priors on the latent functions defining the IRFs. This allows us to simultaneously relax assumptions about the shape of the IRFs while preserving the ability to estimate latent traits. This in turn allows us to easily extend the model to further tasks such as active learning. GPIRT therefore provides a simple and intuitive solution to several longstanding problems in the IRT literature.}
}
